{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python tutorial\n",
    "Python is a very common programming language in machine learning applications and is used in the exercises of this course. This tutorial is targeted for students that have at least elementary knowledge of programming in any language. In particular, you should know basic concepts such as variables, loops and functions. In this document we see how to use those building blocks in Python programs. We also cover some important packages such as NumPy, Pandas and Matplotlib. If you installed the [Anaconda Distribution](https://www.anaconda.com/distribution/) (Python version 3.x recommended) you should already have those packages, in addition to the Python language itself.\n",
    "\n",
    "**Note:** There are exercises in the end of this document.\n",
    "\n",
    "## Jupyter Notebook\n",
    "Jupyter Notebook is an easy way to make documents containing both runnable program code and text (markdown). [Tutorials](https://www.dataquest.io/blog/jupyter-notebook-tutorial/) about Jupyter Notebook are easily found on the Internet but we also cover some of the most important concepts here. \n",
    "\n",
    "Notebook documents consist of two kinds of *cells*: *code* and *Markdown*. Code cells contain executable program code and Markdown cells contain text, possibly with images. You can execute the currently selected cell by pressing either **Ctrl+Enter** or **Shift+Enter**. The latter option also selects the next cell, making it easy to execute multiple consecutive cells after each other. These actions can also be found in the menu: Cell -> Run Cells. The entire Notebook can be executed from the menu: Kernel -> Restart & Run All.\n",
    "\n",
    "To add a new cell, press either a (insert *above* the current cell) or b (*below* the current cell) when a cell is selected but not editable. When editing a cell, pressing a or b will of course just add a letter to the document. To stop editing a cell, you may click the border area. To delete a cell, press d (*delete*) *twice*.\n",
    "\n",
    "It is possible to execute a cell multiple times or to execute cells in an order that is different from their order in the document. This can be handy when you need to make small changes - there is no need to re-execute everything from the beginning. However, you need to remember that the state of the running program is determined by the order in which you run the cells, not by their order in the document.\n",
    "\n",
    "By pressing h (*help*) you can see what keyboard shortcuts are available. You can also access everything from the menus but it is faster to memorize at least the most commonly used keyboard shortcuts such as adding and executing cells.\n",
    "\n",
    "## Python programming basics\n",
    "As our simplest use case, we can easily compute the values of certain expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5 + 8*6 # Execute the cell by pressing Shift+Enter or Ctrl+Enter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using variables is similar to other languages, although in Python there is no separate variable declaration. The data type of a variable depends on what is assigned to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = 5\n",
    "b, c = -1, 1              # We can assign values to more than one variable at the same time\n",
    "s, x = 'a string', 2.1\n",
    "print(a*b + x*c)\n",
    "print(a**b)               # Exponentiation\n",
    "print(s + ' ' + str(a))   # An explicit conversion of a number to a string is necessary here\n",
    "b, c = c, b               # Swap the values of two variables\n",
    "print(b, c)\n",
    "s = a                     # Now s is no longer a string\n",
    "print(s, type(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional statements and loops\n",
    "Conditional statements and loops are similar to most programming languages. The 'for' loop of Python iterates over a collection. To iterate over a range of numeric values, we can use the *range()* function. Range can take a lower limit, an upper limit and a step size as the parameters. If only one parameter is specified, it is the upper limit (which is itself excluded), lower limit is 0 and step size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if b > 0:                          # A conditional statement\n",
    "    print('Positive')\n",
    "elif b < 0:                        # There can be any number of \"else if\" -branches, including 0\n",
    "    print('Negative')\n",
    "else:                              # At most one \"else\"-branch\n",
    "    print('Zero')\n",
    "    \n",
    "print()\n",
    "    \n",
    "for i in [-1, 1, -2, 6]:           # Iterate over a list\n",
    "    print(i, i**2)\n",
    "    \n",
    "print()\n",
    "    \n",
    "for i in range(10):                # Repeat for i = 0, 1, ..., 9 (the upper limit, 10, is excluded)\n",
    "    print(i)\n",
    "    \n",
    "print()\n",
    "    \n",
    "for i in range(-3, 8, 2):          # Repeat for i = -3, -1, ..., 7\n",
    "    print(i)\n",
    "\n",
    "print()\n",
    "\n",
    "i = -3\n",
    "while i < 8:                       # The same as above but with a while loop\n",
    "    print(i)\n",
    "    i += 2                         # Here we must remember to increase the value of i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indentation\n",
    "As seen above, in Python code blocks are defined by *indentation*, not by any particular block start and end characters (like '{' and '}' in Java). Some lines need to be ended in a colon (':'), e.g. conditional statements, loops and function definitions.\n",
    "\n",
    "### Functions\n",
    "Functions are defined using the 'def' keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):           # A function definition\n",
    "    return x**2\n",
    "\n",
    "f(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data structures\n",
    "The core language provides several data structures, such as 'list', 'tuple' and 'dictionary'. Lists and tuples are simple collections of values. Dictionaries consist of key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1, 2, 3]              # A list\n",
    "t = (1, 2, 3)              # A tuple - similar to a list but cannot be modified after creation\n",
    "l[0] = 0                   # t[0] would not work because tuples are immutable\n",
    "d = {'zero': 0, 'one': 1}  # A dictionary\n",
    "print(l, t, d)\n",
    "print(l[1], d['one'])      # l[1] is the second element of l - first index is 0\n",
    "print(t[0:2])              # Elements at index 0 and 1 (end index is excluded)\n",
    "print(t[0:3:2])            # Start index 0, end index 3, step size 2\n",
    "print(t[::-1])             # Step size -1 (reverse), include all elements (start and end index empty)\n",
    "l.append(4)                # Append an element to the end of a list\n",
    "d['many'] = 3              # Add a new key-value pair to a dictionary\n",
    "print(l, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nice to know, not essential for this course:\n",
    "There are many handy features in Python that you can use to save some work: list comprehensions, filter and map functions, lambda functions (a lambda function is an unnamed function that is defined where it is used). Here are some examples but we won't cover them any further because our needs are quite modest in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [x**2 for x in l]                   # List comprehension - can replace a loop in many cases\n",
    "l2 = [x**2 for x in l if x > 0]          # List comprehension with some elements omitted\n",
    "print(l1, l2)\n",
    "print(list(filter(lambda x: x > 0, l1))) # Filter: include only positive elements\n",
    "print(list(map(lambda x: x**2, l1)))     # Map: apply a function to all elements of a collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy\n",
    "NumPy provides us with multi-dimensional arrays and methods for working with them. Among the methods are dot products of vectors, matrix products, calculating means and standard deviations, generating random numbers and many, many more. Let's start with the basics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vec1 = np.array([1, 2, 3])                          # A one-dimensional array (vector)\n",
    "vec2 = np.array([1, 1, -1])\n",
    "print(np.dot(vec1, vec2))                           # Dot product of vectors\n",
    "print()\n",
    "mat = np.array([[1, 1, 1], [1, -1, 1], [1, 1, -1]]) # A two-dimensional array (matrix)\n",
    "print(mat)\n",
    "print()\n",
    "print(mat@vec1)                                     # Matrix product (vec1 is interpreted as a column vector)\n",
    "print()\n",
    "print(mat*vec1)                                     # Element-wise product, with broadcasting\n",
    "print()\n",
    "print(mat.T)                                        # Transpose of a matrix\n",
    "print()\n",
    "print(np.linalg.inv(mat))                           # Inverse of a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that matrix product is denoted by the symbol @, not by * which is used for scalar multiplication or for element-wise product of the elements of two matrices. For example, if A and B are 3x3-matrices, (A\\*B)[0, 0] = A[0]\\*B[0] whereas (A@B)[0, 0] = A[0, 0]\\*B[0, 0] + A[0, 1]\\*B[1, 0] + A[0, 2]\\*B[2, 0].\n",
    "\n",
    "Above, we used the operator \\* where the left-side object was a matrix, but on the right there was a vector. This works because of an automatically applied mechanism known as *broadcasting*. Conceptually, the vector [1, 2, 3] (here interpreted as a row vector) was repeated three times to get a 3x3-matrix with all rows equal to [1, 2, 3]. The matrix mat was then multiplied element-wise with this new matrix.\n",
    "\n",
    "In most applications we don't want to enter the arrays manually as that would be tedious and error-prone. Instead, we may read data (here, the [well-known Iris data set](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/), iris.data) from a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data = np.loadtxt('iris.data', dtype='object', delimiter=',')\n",
    "print(orig_data)\n",
    "# We see that only the four first columns are numeric, the fifth is the species. Let's get the\n",
    "# numeric attributes into one array (contains numbers) and the species into a vector\n",
    "X, y = orig_data[:, 0:4].astype(float), orig_data[:, 4]\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a description of what the columns represent, see [the Iris data set page](https://archive.ics.uci.edu/ml/datasets/iris) (Attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the column names later\n",
    "col_names = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the means of all four attributes. First, for all four classes of the flowers. Then, for Iris setosa only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(X, axis=0))\n",
    "print(np.mean(X[y == 'Iris-setosa'], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the parameter 'axis' specifies that we are interested in column-wise means (0 actually means *rows*; one needs to *iterate over all rows* to get the mean value of a column). If we don't specify any axis, we will get the mean of all values of the array.\n",
    "\n",
    "In the second case we created a *Boolean vector* by the condition 'y == 'Iris-setosa''. The condition is *True* for all rows where the flower is of class 'Iris-setosa' and *False* for all other rows. Such a vector can be used to index an array. The result is that a row of the array is included if and only if the Boolean vector contains the value *True* in the corresponding position. The size of the Boolean vector should be equal to the number of rows in the array. We could also use a vector containing the indices of the wanted rows, and such a vector can be obtained using the 'where' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(X[np.where(y=='Iris-setosa')], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate many kinds of random sequences with NumPy. This includes samples from various kinds of statistical distributions or randomly selected samples from a given collection, with or without replacement. The latter case, samples from a collection without replacement, are also *permutations*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(np.random.uniform(low=1, high=3, size=20))                   # Samples from a uniform distributions\n",
    "shuffled_classes = np.random.choice(y, size=len(y), replace=False) # Random permutation of y\n",
    "print(shuffled_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "NumPy is a powerful library but for interactively working with tabular data it is not always ideal. For instance, we would quite likely want to *label* our columns in some way so that we don't need to look at a separate vector containing the labels whenever we have forgotten what the columns stand for. We might also want to use those labels as column indices instead of always using numbers from zero to the number of columns minus one. Perhaps we would like to do the same with rows, too.\n",
    "\n",
    "Pandas is a package providing just that and more. The basic data structures of Pandas are Series (1D array, similar to a NumPy vector but item indices (labels) need not be integers) and DataFrame (similar to 2D NumPy array, with freely selectable row and column labels).\n",
    "\n",
    "Let's load the Iris data into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Way 1: from a file\n",
    "df1 = pd.read_csv('iris.data', names=col_names)\n",
    "# Way 2: from a NumPy array\n",
    "df2 = pd.DataFrame(orig_data, columns=col_names)\n",
    "print(df1.dtypes, df2.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the two ways of getting the data led to different data types of the columns. This is because in the NumPy array all values were of type object. In a Pandas DataFrame different columns can have different data types but in NumPy arrays that is not supported.\n",
    "\n",
    "If we want to work with Pandas instead of NumPy, we would usually prefer the first way. The read_csv funtion of Pandas can also get the names of the columns from the file. Had we omitted 'names=col_names', the first row of the file would have been used as column names. In the present case that does not make sense because the file does not contain column labels. If numbers 0, 1, ... are acceptable as column names, we could omit the names parameter and add a new parameter 'header=None'. If some column contains values that we want to use as row names, we can add the parameter 'index_col= &lt;column number or name&gt;'.\n",
    "\n",
    "Now that we have loaded the data, let's do something with it. Like with NumPy, we can compute row and column means and select rows or columns from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.mean()) \n",
    "print(df1.mean(axis=1))          # Row means\n",
    "setosa = df1[df1['class'] == 'Iris-setosa']\n",
    "print(setosa.mean())             # Attribute (column) means for Iris setosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw above, the syntax is slightly different from NumPy when we want to compute, e.g., the means of some columns. Here, mean is a function (method) of the DataFrame object and it is therefore called like 'df1.mean()', whereas in NumPy we used 'np.mean(X, axis=0)'. Also note that with Pandas we did not get the mean of the entire array when we did not specify an axis.\n",
    "\n",
    "We can convert a Pandas DataFrame to a NumPy array. The recommended way to do that depends on Pandas version. In older versions of Pandas one can use df.values, and the newer versions also support a method df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df1.iloc[:, 0:4].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we converted a part of the DataFrame into a NumPy array and then computed the mean of all values.\n",
    "\n",
    "There are many ways to index a DataFrame. One can use df[&lt;column name&gt;], df[Boolean_vector], df.loc[...] and df.iloc[...]. The first two can be a bit confusing at first. This is because the first one selects columns and the second one selects rows, despite the calls looking very similar to each other. Also, in NumPy we can select several rows of an array by a vector of row indices but in Pandas df[vector_of_labels] selects columns (unlike df[Boolean_vector] which selects rows).\n",
    "\n",
    "To select rows or colums by numeric indices instead of row/column labels, one can use df.iloc[rows, columns]. Above, we selected all rows (indices ':' on the first axis) and four first columns (indices '0:4' on the second axis). When using iloc, the labels of the rows and columns are ignored, even if they happen to be numbers.\n",
    "\n",
    "The final way, df.loc[rows, columns] works similarly to iloc but selection is done by row and column labels. One difference is that, for example, df.loc[:, start:end] contains also the column df[end] whereas it is omitted when using iloc. Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df1['class'])                           # Select a column by name\n",
    "print(df1.iloc[:5, 4])                        # Select 5 rows and one column by index\n",
    "print(df1.iloc[:5, 0:4])                      # Select 5 rows and 4 columns by index\n",
    "print(df1.loc[:5, 'sepal length':'class'])    # Select 5 rows and columns between 'sepal length' and 'class' -\n",
    "                                              # including the column 'class'. Here that selects all columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can also compute correlations and draw scatter plots and histograms for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.corr()           # Correlations between columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Without the above line the figure may not be shown. This 'magic incantation' is only needed once in a Jupyter\n",
    "# Notebook document, before the first time we draw a figure.\n",
    "\n",
    "pd.plotting.scatter_matrix(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas offers many functionalities not covered in this tutorial. For instance, one can make queries involving multiple tables, join tables etc. For more details, see [comparison with SQL](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_sql.html). However, we won't need advanced functionality during this course. So, let's proceed to the next topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib\n",
    "When we get a new data set, we usually want to make different kinds of plots to see what is in the data. There are other use cases for plots, too, such as reporting our results in a visual way. Matplotlib is one of many possible tools for visualization. Basic usage of Matplotlib is quite easy but more advanced plotting can be a bit cumbersome. In this course our needs are relatively simple.\n",
    "\n",
    "Let's start by plotting a function of one variable $y=f(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 2*np.pi, 50)\n",
    "y = np.sin(x)\n",
    "\n",
    "plt.plot(x, y, 'o', color='blue')              # Draw points without connecting them by line segments\n",
    "plt.plot(x, y, color='black')                  # Connect consecutive points with line segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to make a plot consisting of several subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(df1['sepal length'])                         # Histogram\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(df1['sepal length'], df1['petal length']) # Scatter plot\n",
    "\n",
    "# Next, we will try plotting a Pandas DataFrame. First we put some data to the DataFrame\n",
    "plt.subplot(2, 2, 3)\n",
    "x2 = np.linspace(10, 20, 500)\n",
    "y2 = np.sin(x2)\n",
    "y3 = np.cos(x2)\n",
    "y4 = y2/x2\n",
    "df = pd.DataFrame(columns=['sin(x)', 'cos(x)', 'sin(x)/x'])\n",
    "df['sin(x)'] = y2\n",
    "df['cos(x)'] = y3\n",
    "df['sin(x)/x'] = y4\n",
    "df = df.set_index(x2)\n",
    "plt.plot(df)                            # Plots all columns of the data frame\n",
    "plt.legend(df.columns)                  # Let's add a legend - although it won't look nice here\n",
    "\n",
    "# If we plot a sequence of y values, the x values will be 0, 1, ... in the plot. Here,\n",
    "# that gives a rather misleading impression of the function we are plotting.\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(df['sin(x)'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a title and axis labels to a plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1['sepal length'], df1['petal length'])\n",
    "plt.title('Sepal and petal length')\n",
    "plt.xlabel('Sepal length (cm)')\n",
    "plt.ylabel('Petal length (cm)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to know Matplotlib in greater detail, you might check, for example, [Pyplot tutorial](https://matplotlib.org/3.1.1/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py).\n",
    "\n",
    "But now, it is time for some exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "Use the included data matrix 'exercise_data.csv'. Solve the following exercises:\n",
    "\n",
    "1. Load the data into a Pandas data frame.\n",
    "1. Find all objects of class 1 whose height is over 25 units. Print all of their attributes. *Hint*: you can combine the results of two comparisons using the '&' operator (class is 1 *and* height is over 25). Parentheses may be needed.\n",
    "1. Compute the mean of each attribute for the whole data.\n",
    "1. Make a plot of weights (y axis) vs. heights (x axis).\n",
    "1. Make a plot of weights (y axis) vs. \"size\" (=$height \\cdot width^2$, x axis).\n",
    "1. Like 4-5 but limited to objects of class 1.\n",
    "1. Do you see anything interesting in the plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
